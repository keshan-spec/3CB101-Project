{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import twint\n",
    "import pandas as pd\n",
    "\n",
    "# sentiment analysis\n",
    "from optimus import Optimus\n",
    "from textblob import TextBlob\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "op = Optimus()\n",
    "\n",
    "# For notebooks \n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/analyzing-tweets-with-nlp-in-minutes-with-spark-optimus-and-twint-a0c96084995f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configuration\n",
    "FILENAME = 'tweets.json'\n",
    "\n",
    "config = twint.Config()\n",
    "config.Search = \"bitcoin\"\n",
    "#config.Lang = \"en\"\n",
    "config.Limit = 1\n",
    "# config.Since = \"2019-04-29 00:00:00\" #datetime.strptime(\"2019-04-29 00:00:00\", '%Y-%m-%d %H:%M:%S')\n",
    "#config.Until = \"2020-04-29 12:00:00\" # datetime.strptime(\"2020–04–29 12:00:00\", '%Y-%m-%d %H:%M:%S')\n",
    "#config.Min_likes = 500\n",
    "config.Pandas = True\n",
    "config.Hide_output = True\n",
    "\n",
    "#running search\n",
    "twint.run.Search(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/FavioVazquez/twitter_optimus_twint/blob/master/AnalyzeTweets.ipynb\n",
    "\n",
    "# return all the columns in the twint output\n",
    "def available_columns():\n",
    "    return twint.output.panda.Tweets_df.columns\n",
    "\n",
    "# return only the needed columns for analysis\n",
    "def twint_to_pandas(columns):\n",
    "    return twint.output.panda.Tweets_df[columns]\n",
    "\n",
    "# Function to get sentiment\n",
    "def apply_blob(sentence):\n",
    "    temp = TextBlob(sentence).sentiment[0]\n",
    "    if temp == 0.0:\n",
    "        return 0.0  # Neutral\n",
    "    elif temp >= 0.0:\n",
    "        return 1.0  # Positive\n",
    "    else:\n",
    "        return 2.0  # Negative\n",
    "\n",
    "# UDF to write sentiment on DF\n",
    "sentiment = udf(apply_blob, DoubleType())\n",
    "\n",
    "def create_optimus(df):\n",
    "    # Transform Pandas DF to Optimus/Spark DF\n",
    "    df = op.create.data_frame(pdf=df)\n",
    "\n",
    "    # Clean tweets\n",
    "    clean_tweets = df.cols.remove_accents(\"tweet\").cols.remove_special_chars(\"tweet\")\n",
    "\n",
    "    # Add sentiment to final DF\n",
    "    return clean_tweets.withColumn(\"sentiment\", sentiment(clean_tweets['tweet']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(available_columns())\n",
    "\n",
    "df = twint_to_pandas([\"date\", \"username\", \"tweet\", \"hashtags\", \"nlikes\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the Optimus DataFrame \n",
    "op_df = create_optimus(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ERROR: Java error,\n",
    "# IllegalArgumentException: 'Unsupported class file major version 57'\n",
    "op_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## THIS SECTION IS FOR WHEN THE TWITTER DATA IS SAVED AS A JSON FILE\n",
    "# config.Store_json = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modifying json file\n",
    "import json\n",
    "\n",
    "# Reading the json\n",
    "with open(FILENAME, encoding=\"utf8\") as json_data:\n",
    "    data = json.load(json_data)\n",
    "    \n",
    "    # store the data as a pandas dataframe\n",
    "    df= pd.DataFrame(data[\"tweets\"])\n",
    "\n",
    "# Drop all the columns and rows that conatin null values\n",
    "df.dropna(axis=0, how=\"any\", inplace=False)\n",
    "\n",
    "# drop all the rows that do not affect the sentiment\n",
    "unwanted_cols = [\"id\", \"created_at\", \"conversation_id\", \"timezone\", \"urls\", \"photos\", \"thumbnail\", \"near\", \"geo\", \"user_rt_id\", \"user_rt\", \"retweet_id\",\n",
    "                 \"reply_to\", \"translate\", \"trans_src\", \"trans_dest\", \"cashtags\", \"retweet_date\", \"retweet\", \"video\", \"source\", \"quote_url\", \"place\"]\n",
    "df.drop(unwanted_cols, axis=1, inplace=True)\n",
    "\n",
    "# create a new Date column consisting of a concatinated string of the date and time columns\n",
    "# drop the date and time columns from the dataframe\n",
    "# and set the Date column as the index of the dataframe\n",
    "df['Date'] = df['date'].str.cat(df['time'], sep=\" \")\n",
    "df.drop([\"date\", \"time\"], axis=1, inplace=True)\n",
    "df.set_index('Date', inplace=True)\n",
    "\n",
    "#print(df.columns)\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fd826fe865dcc411e912db3b8b9b4ce519949da90518879d30f3fbad62980482"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('Tensor': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
