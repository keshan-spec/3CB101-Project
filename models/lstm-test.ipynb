{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```` \n",
    "https://machinelearningmastery.com/multivariate-time-series-forecasting-lstms-keras/\n",
    "https://machinelearningmastery.com/suitability-long-short-term-memory-networks-time-series-forecasting/\n",
    "https://sailajakarra.medium.com/lstm-for-time-series-predictions-cc68cc11ce4f\n",
    " ````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>estimated-transaction-volume-usd</th>\n",
       "      <th>n-transactions</th>\n",
       "      <th>hash-rate</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>cost-per-transaction</th>\n",
       "      <th>Gold price</th>\n",
       "      <th>output-volume</th>\n",
       "      <th>trade-volume</th>\n",
       "      <th>USD-CNY Price</th>\n",
       "      <th>SVI</th>\n",
       "      <th>Wikiviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15470.656119</td>\n",
       "      <td>15446.307986</td>\n",
       "      <td>15900.046760</td>\n",
       "      <td>14932.582596</td>\n",
       "      <td>2.004009e+09</td>\n",
       "      <td>282361.699343</td>\n",
       "      <td>7.478909e+07</td>\n",
       "      <td>1.034516e+13</td>\n",
       "      <td>72.066568</td>\n",
       "      <td>1377.316553</td>\n",
       "      <td>1.084341e+06</td>\n",
       "      <td>3.828892e+08</td>\n",
       "      <td>6.72991</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.290015</td>\n",
       "      <td>31.511729</td>\n",
       "      <td>27.977000</td>\n",
       "      <td>33.278400</td>\n",
       "      <td>1.131921e+08</td>\n",
       "      <td>110449.000000</td>\n",
       "      <td>6.316950e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-3.563874</td>\n",
       "      <td>-82.716553</td>\n",
       "      <td>1.573982e+06</td>\n",
       "      <td>2.832723e+06</td>\n",
       "      <td>0.21509</td>\n",
       "      <td>18.574713</td>\n",
       "      <td>9165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.381003</td>\n",
       "      <td>20.287779</td>\n",
       "      <td>4.159823</td>\n",
       "      <td>19.578350</td>\n",
       "      <td>6.177315e+07</td>\n",
       "      <td>10713.000000</td>\n",
       "      <td>6.316950e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.064860</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.950525e+06</td>\n",
       "      <td>1.502055e+06</td>\n",
       "      <td>0.01600</td>\n",
       "      <td>18.574713</td>\n",
       "      <td>12354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.489436</td>\n",
       "      <td>18.382769</td>\n",
       "      <td>109.744904</td>\n",
       "      <td>21.750954</td>\n",
       "      <td>9.192380e+07</td>\n",
       "      <td>26978.000000</td>\n",
       "      <td>-1.579238e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.414935</td>\n",
       "      <td>-8.300000</td>\n",
       "      <td>2.482038e+06</td>\n",
       "      <td>1.016058e+06</td>\n",
       "      <td>-0.02590</td>\n",
       "      <td>18.574713</td>\n",
       "      <td>10757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-134.379897</td>\n",
       "      <td>100.489420</td>\n",
       "      <td>18.829302</td>\n",
       "      <td>-152.846166</td>\n",
       "      <td>1.321019e+08</td>\n",
       "      <td>-40141.000000</td>\n",
       "      <td>-2.210933e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.087133</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>2.998215e+06</td>\n",
       "      <td>1.452953e+07</td>\n",
       "      <td>-0.04510</td>\n",
       "      <td>18.574713</td>\n",
       "      <td>11938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          close          open          high           low  \\\n",
       "0  15470.656119  15446.307986  15900.046760  14932.582596   \n",
       "1     20.290015     31.511729     27.977000     33.278400   \n",
       "2     18.381003     20.287779      4.159823     19.578350   \n",
       "3    100.489436     18.382769    109.744904     21.750954   \n",
       "4   -134.379897    100.489420     18.829302   -152.846166   \n",
       "\n",
       "   estimated-transaction-volume-usd  n-transactions     hash-rate  \\\n",
       "0                      2.004009e+09   282361.699343  7.478909e+07   \n",
       "1                      1.131921e+08   110449.000000  6.316950e+04   \n",
       "2                      6.177315e+07    10713.000000  6.316950e+04   \n",
       "3                      9.192380e+07    26978.000000 -1.579238e+05   \n",
       "4                      1.321019e+08   -40141.000000 -2.210933e+05   \n",
       "\n",
       "     difficulty  cost-per-transaction   Gold price  output-volume  \\\n",
       "0  1.034516e+13             72.066568  1377.316553   1.084341e+06   \n",
       "1  0.000000e+00             -3.563874   -82.716553   1.573982e+06   \n",
       "2  0.000000e+00              0.064860     1.000000   1.950525e+06   \n",
       "3  0.000000e+00             -0.414935    -8.300000   2.482038e+06   \n",
       "4  0.000000e+00             -0.087133     0.100000   2.998215e+06   \n",
       "\n",
       "   trade-volume  USD-CNY Price        SVI  Wikiviews  \n",
       "0  3.828892e+08        6.72991   7.000000       3139  \n",
       "1  2.832723e+06        0.21509  18.574713       9165  \n",
       "2  1.502055e+06        0.01600  18.574713      12354  \n",
       "3  1.016058e+06       -0.02590  18.574713      10757  \n",
       "4  1.452953e+07       -0.04510  18.574713      11938  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get data\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"./data/differenced_df.csv\", index_col=0, parse_dates=True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.indexes.numeric.Int64Index"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    " \n",
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg\n",
    " \n",
    "# get dataset\n",
    "values = df.values\n",
    "# integer encode direction\n",
    "encoder = LabelEncoder()\n",
    "values[:,4] = encoder.fit_transform(values[:,4])\n",
    "# ensure all data is float\n",
    "values = values.astype('float32')\n",
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, 1, 1)\n",
    "\n",
    "# drop columns we don't want to predict\n",
    "# reframed.drop(reframed.columns[[9,10,11,12,13,14,15]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-1)</th>\n",
       "      <th>var2(t-1)</th>\n",
       "      <th>var3(t-1)</th>\n",
       "      <th>var4(t-1)</th>\n",
       "      <th>var5(t-1)</th>\n",
       "      <th>var6(t-1)</th>\n",
       "      <th>var7(t-1)</th>\n",
       "      <th>var8(t-1)</th>\n",
       "      <th>var9(t-1)</th>\n",
       "      <th>var10(t-1)</th>\n",
       "      <th>...</th>\n",
       "      <th>var6(t)</th>\n",
       "      <th>var7(t)</th>\n",
       "      <th>var8(t)</th>\n",
       "      <th>var9(t)</th>\n",
       "      <th>var10(t)</th>\n",
       "      <th>var11(t)</th>\n",
       "      <th>var12(t)</th>\n",
       "      <th>var13(t)</th>\n",
       "      <th>var14(t)</th>\n",
       "      <th>var15(t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.692236</td>\n",
       "      <td>0.688081</td>\n",
       "      <td>0.695887</td>\n",
       "      <td>0.684940</td>\n",
       "      <td>0.957808</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.894101</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.592718</td>\n",
       "      <td>0.510186</td>\n",
       "      <td>0.293512</td>\n",
       "      <td>0.509416</td>\n",
       "      <td>0.224679</td>\n",
       "      <td>0.047789</td>\n",
       "      <td>0.349364</td>\n",
       "      <td>0.093454</td>\n",
       "      <td>0.15182</td>\n",
       "      <td>0.058838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.500800</td>\n",
       "      <td>0.495496</td>\n",
       "      <td>0.500765</td>\n",
       "      <td>0.495956</td>\n",
       "      <td>0.642192</td>\n",
       "      <td>0.592718</td>\n",
       "      <td>0.510186</td>\n",
       "      <td>0.293512</td>\n",
       "      <td>0.509416</td>\n",
       "      <td>0.224679</td>\n",
       "      <td>...</td>\n",
       "      <td>0.356432</td>\n",
       "      <td>0.510186</td>\n",
       "      <td>0.293512</td>\n",
       "      <td>0.527873</td>\n",
       "      <td>0.269135</td>\n",
       "      <td>0.063409</td>\n",
       "      <td>0.349117</td>\n",
       "      <td>0.065750</td>\n",
       "      <td>0.15182</td>\n",
       "      <td>0.083439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.500776</td>\n",
       "      <td>0.495355</td>\n",
       "      <td>0.500473</td>\n",
       "      <td>0.495782</td>\n",
       "      <td>0.590685</td>\n",
       "      <td>0.356432</td>\n",
       "      <td>0.510186</td>\n",
       "      <td>0.293512</td>\n",
       "      <td>0.527873</td>\n",
       "      <td>0.269135</td>\n",
       "      <td>...</td>\n",
       "      <td>0.394965</td>\n",
       "      <td>0.508736</td>\n",
       "      <td>0.293512</td>\n",
       "      <td>0.525433</td>\n",
       "      <td>0.264196</td>\n",
       "      <td>0.085457</td>\n",
       "      <td>0.349027</td>\n",
       "      <td>0.059920</td>\n",
       "      <td>0.15182</td>\n",
       "      <td>0.071119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.501794</td>\n",
       "      <td>0.495332</td>\n",
       "      <td>0.501771</td>\n",
       "      <td>0.495810</td>\n",
       "      <td>0.621370</td>\n",
       "      <td>0.394965</td>\n",
       "      <td>0.508736</td>\n",
       "      <td>0.293512</td>\n",
       "      <td>0.525433</td>\n",
       "      <td>0.264196</td>\n",
       "      <td>...</td>\n",
       "      <td>0.235952</td>\n",
       "      <td>0.508322</td>\n",
       "      <td>0.293512</td>\n",
       "      <td>0.527100</td>\n",
       "      <td>0.268657</td>\n",
       "      <td>0.106870</td>\n",
       "      <td>0.351540</td>\n",
       "      <td>0.057248</td>\n",
       "      <td>0.15182</td>\n",
       "      <td>0.080230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.498883</td>\n",
       "      <td>0.496357</td>\n",
       "      <td>0.500653</td>\n",
       "      <td>0.493595</td>\n",
       "      <td>0.656438</td>\n",
       "      <td>0.235952</td>\n",
       "      <td>0.508322</td>\n",
       "      <td>0.293512</td>\n",
       "      <td>0.527100</td>\n",
       "      <td>0.268657</td>\n",
       "      <td>...</td>\n",
       "      <td>0.468233</td>\n",
       "      <td>0.511945</td>\n",
       "      <td>0.293512</td>\n",
       "      <td>0.521722</td>\n",
       "      <td>0.269241</td>\n",
       "      <td>0.111119</td>\n",
       "      <td>0.351101</td>\n",
       "      <td>0.067796</td>\n",
       "      <td>0.15182</td>\n",
       "      <td>0.067833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   var1(t-1)  var2(t-1)  var3(t-1)  var4(t-1)  var5(t-1)  var6(t-1)  \\\n",
       "1   0.692236   0.688081   0.695887   0.684940   0.957808   1.000000   \n",
       "2   0.500800   0.495496   0.500765   0.495956   0.642192   0.592718   \n",
       "3   0.500776   0.495355   0.500473   0.495782   0.590685   0.356432   \n",
       "4   0.501794   0.495332   0.501771   0.495810   0.621370   0.394965   \n",
       "5   0.498883   0.496357   0.500653   0.493595   0.656438   0.235952   \n",
       "\n",
       "   var7(t-1)  var8(t-1)  var9(t-1)  var10(t-1)  ...   var6(t)   var7(t)  \\\n",
       "1   1.000000   1.000000   0.894101    1.000000  ...  0.592718  0.510186   \n",
       "2   0.510186   0.293512   0.509416    0.224679  ...  0.356432  0.510186   \n",
       "3   0.510186   0.293512   0.527873    0.269135  ...  0.394965  0.508736   \n",
       "4   0.508736   0.293512   0.525433    0.264196  ...  0.235952  0.508322   \n",
       "5   0.508322   0.293512   0.527100    0.268657  ...  0.468233  0.511945   \n",
       "\n",
       "    var8(t)   var9(t)  var10(t)  var11(t)  var12(t)  var13(t)  var14(t)  \\\n",
       "1  0.293512  0.509416  0.224679  0.047789  0.349364  0.093454   0.15182   \n",
       "2  0.293512  0.527873  0.269135  0.063409  0.349117  0.065750   0.15182   \n",
       "3  0.293512  0.525433  0.264196  0.085457  0.349027  0.059920   0.15182   \n",
       "4  0.293512  0.527100  0.268657  0.106870  0.351540  0.057248   0.15182   \n",
       "5  0.293512  0.521722  0.269241  0.111119  0.351101  0.067796   0.15182   \n",
       "\n",
       "   var15(t)  \n",
       "1  0.058838  \n",
       "2  0.083439  \n",
       "3  0.071119  \n",
       "4  0.080230  \n",
       "5  0.067833  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reframed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 1, 29) (1460,) (365, 1, 29) (365,)\n"
     ]
    }
   ],
   "source": [
    "# split data\n",
    "values = reframed.values\n",
    "n_train_days = 365 * 4\n",
    "train = values[:n_train_days, :]\n",
    "test = values[n_train_days:, :]\n",
    "\n",
    "# split into input and outputs\n",
    "train_X, train_y = train[:, :-1], train[:, -1]\n",
    "test_X, test_y = test[:, :-1], test[:, -1]\n",
    "\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_X.shape[0], 1, train_X.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "21/21 - 1s - loss: 0.0656 - val_loss: 0.0927\n",
      "Epoch 2/60\n",
      "21/21 - 0s - loss: 0.0663 - val_loss: 0.0580\n",
      "Epoch 3/60\n",
      "21/21 - 0s - loss: 0.0543 - val_loss: 0.0612\n",
      "Epoch 4/60\n",
      "21/21 - 0s - loss: 0.0541 - val_loss: 0.0579\n",
      "Epoch 5/60\n",
      "21/21 - 0s - loss: 0.0526 - val_loss: 0.0552\n",
      "Epoch 6/60\n",
      "21/21 - 0s - loss: 0.0517 - val_loss: 0.0523\n",
      "Epoch 7/60\n",
      "21/21 - 0s - loss: 0.0503 - val_loss: 0.0508\n",
      "Epoch 8/60\n",
      "21/21 - 0s - loss: 0.0497 - val_loss: 0.0478\n",
      "Epoch 9/60\n",
      "21/21 - 0s - loss: 0.0481 - val_loss: 0.0471\n",
      "Epoch 10/60\n",
      "21/21 - 0s - loss: 0.0476 - val_loss: 0.0452\n",
      "Epoch 11/60\n",
      "21/21 - 0s - loss: 0.0465 - val_loss: 0.0439\n",
      "Epoch 12/60\n",
      "21/21 - 0s - loss: 0.0457 - val_loss: 0.0430\n",
      "Epoch 13/60\n",
      "21/21 - 0s - loss: 0.0453 - val_loss: 0.0413\n",
      "Epoch 14/60\n",
      "21/21 - 0s - loss: 0.0444 - val_loss: 0.0406\n",
      "Epoch 15/60\n",
      "21/21 - 0s - loss: 0.0440 - val_loss: 0.0394\n",
      "Epoch 16/60\n",
      "21/21 - 0s - loss: 0.0433 - val_loss: 0.0383\n",
      "Epoch 17/60\n",
      "21/21 - 0s - loss: 0.0425 - val_loss: 0.0378\n",
      "Epoch 18/60\n",
      "21/21 - 0s - loss: 0.0423 - val_loss: 0.0362\n",
      "Epoch 19/60\n",
      "21/21 - 0s - loss: 0.0414 - val_loss: 0.0360\n",
      "Epoch 20/60\n",
      "21/21 - 0s - loss: 0.0411 - val_loss: 0.0349\n",
      "Epoch 21/60\n",
      "21/21 - 0s - loss: 0.0404 - val_loss: 0.0345\n",
      "Epoch 22/60\n",
      "21/21 - 0s - loss: 0.0397 - val_loss: 0.0339\n",
      "Epoch 23/60\n",
      "21/21 - 0s - loss: 0.0393 - val_loss: 0.0331\n",
      "Epoch 24/60\n",
      "21/21 - 0s - loss: 0.0387 - val_loss: 0.0327\n",
      "Epoch 25/60\n",
      "21/21 - 0s - loss: 0.0382 - val_loss: 0.0321\n",
      "Epoch 26/60\n",
      "21/21 - 0s - loss: 0.0374 - val_loss: 0.0318\n",
      "Epoch 27/60\n",
      "21/21 - 0s - loss: 0.0363 - val_loss: 0.0320\n",
      "Epoch 28/60\n",
      "21/21 - 0s - loss: 0.0359 - val_loss: 0.0317\n",
      "Epoch 29/60\n",
      "21/21 - 0s - loss: 0.0352 - val_loss: 0.0314\n",
      "Epoch 30/60\n",
      "21/21 - 0s - loss: 0.0343 - val_loss: 0.0308\n",
      "Epoch 31/60\n",
      "21/21 - 0s - loss: 0.0335 - val_loss: 0.0300\n",
      "Epoch 32/60\n",
      "21/21 - 0s - loss: 0.0324 - val_loss: 0.0296\n",
      "Epoch 33/60\n",
      "21/21 - 0s - loss: 0.0312 - val_loss: 0.0285\n",
      "Epoch 34/60\n",
      "21/21 - 0s - loss: 0.0301 - val_loss: 0.0282\n",
      "Epoch 35/60\n",
      "21/21 - 0s - loss: 0.0290 - val_loss: 0.0272\n",
      "Epoch 36/60\n",
      "21/21 - 0s - loss: 0.0276 - val_loss: 0.0265\n",
      "Epoch 37/60\n",
      "21/21 - 0s - loss: 0.0260 - val_loss: 0.0261\n",
      "Epoch 38/60\n",
      "21/21 - 0s - loss: 0.0254 - val_loss: 0.0259\n",
      "Epoch 39/60\n",
      "21/21 - 0s - loss: 0.0249 - val_loss: 0.0255\n",
      "Epoch 40/60\n",
      "21/21 - 0s - loss: 0.0245 - val_loss: 0.0252\n",
      "Epoch 41/60\n",
      "21/21 - 0s - loss: 0.0241 - val_loss: 0.0248\n",
      "Epoch 42/60\n",
      "21/21 - 0s - loss: 0.0238 - val_loss: 0.0243\n",
      "Epoch 43/60\n",
      "21/21 - 0s - loss: 0.0234 - val_loss: 0.0238\n",
      "Epoch 44/60\n",
      "21/21 - 0s - loss: 0.0228 - val_loss: 0.0232\n",
      "Epoch 45/60\n",
      "21/21 - 0s - loss: 0.0224 - val_loss: 0.0225\n",
      "Epoch 46/60\n",
      "21/21 - 0s - loss: 0.0222 - val_loss: 0.0219\n",
      "Epoch 47/60\n",
      "21/21 - 0s - loss: 0.0214 - val_loss: 0.0212\n",
      "Epoch 48/60\n",
      "21/21 - 0s - loss: 0.0211 - val_loss: 0.0206\n",
      "Epoch 49/60\n",
      "21/21 - 0s - loss: 0.0208 - val_loss: 0.0199\n",
      "Epoch 50/60\n",
      "21/21 - 0s - loss: 0.0202 - val_loss: 0.0196\n",
      "Epoch 51/60\n",
      "21/21 - 0s - loss: 0.0198 - val_loss: 0.0188\n",
      "Epoch 52/60\n",
      "21/21 - 0s - loss: 0.0194 - val_loss: 0.0181\n",
      "Epoch 53/60\n",
      "21/21 - 0s - loss: 0.0189 - val_loss: 0.0177\n",
      "Epoch 54/60\n",
      "21/21 - 0s - loss: 0.0189 - val_loss: 0.0172\n",
      "Epoch 55/60\n",
      "21/21 - 0s - loss: 0.0181 - val_loss: 0.0171\n",
      "Epoch 56/60\n",
      "21/21 - 0s - loss: 0.0179 - val_loss: 0.0161\n",
      "Epoch 57/60\n",
      "21/21 - 0s - loss: 0.0176 - val_loss: 0.0154\n",
      "Epoch 58/60\n",
      "21/21 - 0s - loss: 0.0174 - val_loss: 0.0150\n",
      "Epoch 59/60\n",
      "21/21 - 0s - loss: 0.0173 - val_loss: 0.0148\n",
      "Epoch 60/60\n",
      "21/21 - 0s - loss: 0.0169 - val_loss: 0.0145\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create model\n",
    "# design network\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from matplotlib import pyplot\n",
    "\n",
    "try:\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mae', optimizer='adam')\n",
    "    # fit network\n",
    "    history = model.fit(train_X, train_y, epochs=60, batch_size=72,\n",
    "                        validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "\n",
    "    # plot history\n",
    "    pyplot.plot(history.history['loss'], label='train')\n",
    "    pyplot.plot(history.history['val_loss'], label='test')\n",
    "    pyplot.legend()\n",
    "    pyplot.show()\n",
    "except Exception as e:\n",
    "    print(\"Error: \", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((None, 1, 29), (365, 1, 29))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.input_shape, test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: \n",
      "in user code:\n",
      "\n",
      "    C:\\Users\\dell-2019\\Anaconda3\\envs\\ML\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1462 predict_function  *\n",
      "        return step_function(self, iterator)\n",
      "    C:\\Users\\dell-2019\\Anaconda3\\envs\\ML\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1452 step_function  **\n",
      "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
      "    C:\\Users\\dell-2019\\Anaconda3\\envs\\ML\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n",
      "        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n",
      "    C:\\Users\\dell-2019\\Anaconda3\\envs\\ML\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n",
      "        return self._call_for_each_replica(fn, args, kwargs)\n",
      "    C:\\Users\\dell-2019\\Anaconda3\\envs\\ML\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n",
      "        return fn(*args, **kwargs)\n",
      "    C:\\Users\\dell-2019\\Anaconda3\\envs\\ML\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1445 run_step  **\n",
      "        outputs = model.predict_step(data)\n",
      "    C:\\Users\\dell-2019\\Anaconda3\\envs\\ML\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1418 predict_step\n",
      "        return self(x, training=False)\n",
      "    C:\\Users\\dell-2019\\Anaconda3\\envs\\ML\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:975 __call__\n",
      "        input_spec.assert_input_compatibility(self.input_spec, inputs,\n",
      "    C:\\Users\\dell-2019\\Anaconda3\\envs\\ML\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:176 assert_input_compatibility\n",
      "        raise ValueError('Input ' + str(input_index) + ' of layer ' +\n",
      "\n",
      "    ValueError: Input 0 of layer sequential_3 is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: [None, 29]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    yhat = model.predict(test_X[0])\n",
    "    print(yhat)\n",
    "except Exception as e:\n",
    "    print(\"Error: \")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  operands could not be broadcast together with shapes (365,29) (15,) (365,29) \n"
     ]
    }
   ],
   "source": [
    "# model summary\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "try:\n",
    "    yhat = model.predict(test_X)\n",
    "    test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "\n",
    "    # invert scaling for forecast\n",
    "    inv_yhat = concatenate((yhat, test_X[:, 1:]), axis=1)\n",
    "    inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "    inv_yhat = inv_yhat[:, 0]\n",
    "\n",
    "    # invert scaling for actual\n",
    "    test_y = test_y.reshape((len(test_y), 1))\n",
    "    inv_y = concatenate((test_y, test_X[:, 1:]), axis=1)\n",
    "    inv_y = scaler.inverse_transform(inv_y)\n",
    "    inv_y = inv_y[:, 0]\n",
    "\n",
    "    # calculate RMSE\n",
    "    rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "    print('Test RMSE: %.3f' % rmse)\n",
    "except Exception as e:\n",
    "    print(\"Error: \", e)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ea81ae92a58e0688f48f2fcfa3a5f0d8c10798c4cde0919c77c6301d45da8892"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('ML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
