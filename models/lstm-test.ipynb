{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```` \n",
    "https://machinelearningmastery.com/multivariate-time-series-forecasting-lstms-keras/\n",
    "https://machinelearningmastery.com/suitability-long-short-term-memory-networks-time-series-forecasting/\n",
    "https://sailajakarra.medium.com/lstm-for-time-series-predictions-cc68cc11ce4f\n",
    " ````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>estimated-transaction-volume-usd</th>\n",
       "      <th>n-transactions</th>\n",
       "      <th>hash-rate</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>cost-per-transaction</th>\n",
       "      <th>Gold price</th>\n",
       "      <th>output-volume</th>\n",
       "      <th>trade-volume</th>\n",
       "      <th>USD-CNY Price</th>\n",
       "      <th>SVI</th>\n",
       "      <th>Wikiviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-01</th>\n",
       "      <td>998.079443</td>\n",
       "      <td>966.567909</td>\n",
       "      <td>1005.074602</td>\n",
       "      <td>961.719392</td>\n",
       "      <td>1.667890e+08</td>\n",
       "      <td>180502.0</td>\n",
       "      <td>2.463611e+06</td>\n",
       "      <td>3.176884e+11</td>\n",
       "      <td>10.914479</td>\n",
       "      <td>1377.316553</td>\n",
       "      <td>1.084341e+06</td>\n",
       "      <td>3.989748e+06</td>\n",
       "      <td>6.72991</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-02</th>\n",
       "      <td>1018.369458</td>\n",
       "      <td>998.079638</td>\n",
       "      <td>1033.051602</td>\n",
       "      <td>994.997792</td>\n",
       "      <td>2.799811e+08</td>\n",
       "      <td>290951.0</td>\n",
       "      <td>2.526780e+06</td>\n",
       "      <td>3.176884e+11</td>\n",
       "      <td>7.350606</td>\n",
       "      <td>1294.600000</td>\n",
       "      <td>1.573982e+06</td>\n",
       "      <td>6.822471e+06</td>\n",
       "      <td>6.94500</td>\n",
       "      <td>18.574713</td>\n",
       "      <td>9165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-03</th>\n",
       "      <td>1036.750461</td>\n",
       "      <td>1018.367417</td>\n",
       "      <td>1037.211425</td>\n",
       "      <td>1014.576142</td>\n",
       "      <td>3.417543e+08</td>\n",
       "      <td>301664.0</td>\n",
       "      <td>2.589950e+06</td>\n",
       "      <td>3.176884e+11</td>\n",
       "      <td>7.415466</td>\n",
       "      <td>1295.600000</td>\n",
       "      <td>1.950525e+06</td>\n",
       "      <td>8.324526e+06</td>\n",
       "      <td>6.96100</td>\n",
       "      <td>18.574713</td>\n",
       "      <td>12354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-04</th>\n",
       "      <td>1137.239897</td>\n",
       "      <td>1036.750186</td>\n",
       "      <td>1146.956329</td>\n",
       "      <td>1036.327096</td>\n",
       "      <td>4.336781e+08</td>\n",
       "      <td>328642.0</td>\n",
       "      <td>2.432026e+06</td>\n",
       "      <td>3.176884e+11</td>\n",
       "      <td>7.000531</td>\n",
       "      <td>1287.300000</td>\n",
       "      <td>2.482038e+06</td>\n",
       "      <td>9.340584e+06</td>\n",
       "      <td>6.93510</td>\n",
       "      <td>18.574713</td>\n",
       "      <td>10757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-05</th>\n",
       "      <td>1002.860000</td>\n",
       "      <td>1137.239606</td>\n",
       "      <td>1165.785631</td>\n",
       "      <td>883.480930</td>\n",
       "      <td>5.657800e+08</td>\n",
       "      <td>288501.0</td>\n",
       "      <td>2.210933e+06</td>\n",
       "      <td>3.176884e+11</td>\n",
       "      <td>6.913398</td>\n",
       "      <td>1287.400000</td>\n",
       "      <td>2.998215e+06</td>\n",
       "      <td>2.387011e+07</td>\n",
       "      <td>6.89000</td>\n",
       "      <td>18.574713</td>\n",
       "      <td>11938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  close         open         high          low  \\\n",
       "2017-01-01   998.079443   966.567909  1005.074602   961.719392   \n",
       "2017-01-02  1018.369458   998.079638  1033.051602   994.997792   \n",
       "2017-01-03  1036.750461  1018.367417  1037.211425  1014.576142   \n",
       "2017-01-04  1137.239897  1036.750186  1146.956329  1036.327096   \n",
       "2017-01-05  1002.860000  1137.239606  1165.785631   883.480930   \n",
       "\n",
       "            estimated-transaction-volume-usd  n-transactions     hash-rate  \\\n",
       "2017-01-01                      1.667890e+08        180502.0  2.463611e+06   \n",
       "2017-01-02                      2.799811e+08        290951.0  2.526780e+06   \n",
       "2017-01-03                      3.417543e+08        301664.0  2.589950e+06   \n",
       "2017-01-04                      4.336781e+08        328642.0  2.432026e+06   \n",
       "2017-01-05                      5.657800e+08        288501.0  2.210933e+06   \n",
       "\n",
       "              difficulty  cost-per-transaction   Gold price  output-volume  \\\n",
       "2017-01-01  3.176884e+11             10.914479  1377.316553   1.084341e+06   \n",
       "2017-01-02  3.176884e+11              7.350606  1294.600000   1.573982e+06   \n",
       "2017-01-03  3.176884e+11              7.415466  1295.600000   1.950525e+06   \n",
       "2017-01-04  3.176884e+11              7.000531  1287.300000   2.482038e+06   \n",
       "2017-01-05  3.176884e+11              6.913398  1287.400000   2.998215e+06   \n",
       "\n",
       "            trade-volume  USD-CNY Price        SVI  Wikiviews  \n",
       "2017-01-01  3.989748e+06        6.72991   7.000000       3139  \n",
       "2017-01-02  6.822471e+06        6.94500  18.574713       9165  \n",
       "2017-01-03  8.324526e+06        6.96100  18.574713      12354  \n",
       "2017-01-04  9.340584e+06        6.93510  18.574713      10757  \n",
       "2017-01-05  2.387011e+07        6.89000  18.574713      11938  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get data\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"../data/complete-merged-df.csv\", index_col=0, parse_dates=True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    " \n",
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg\n",
    " \n",
    "# get dataset\n",
    "values = df.values\n",
    "# ensure all data is float\n",
    "values = values.astype('float32')\n",
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, 1, 1)\n",
    "\n",
    "# drop columns we don't want to predict\n",
    "# reframed.drop(reframed.columns[[9,10,11,12,13,14,15]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-1)</th>\n",
       "      <th>var2(t-1)</th>\n",
       "      <th>var3(t-1)</th>\n",
       "      <th>var4(t-1)</th>\n",
       "      <th>var5(t-1)</th>\n",
       "      <th>var6(t-1)</th>\n",
       "      <th>var7(t-1)</th>\n",
       "      <th>var8(t-1)</th>\n",
       "      <th>var9(t-1)</th>\n",
       "      <th>var10(t-1)</th>\n",
       "      <th>...</th>\n",
       "      <th>var6(t)</th>\n",
       "      <th>var7(t)</th>\n",
       "      <th>var8(t)</th>\n",
       "      <th>var9(t)</th>\n",
       "      <th>var10(t)</th>\n",
       "      <th>var11(t)</th>\n",
       "      <th>var12(t)</th>\n",
       "      <th>var13(t)</th>\n",
       "      <th>var14(t)</th>\n",
       "      <th>var15(t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003283</td>\n",
       "      <td>0.002811</td>\n",
       "      <td>0.002673</td>\n",
       "      <td>0.003249</td>\n",
       "      <td>0.003761</td>\n",
       "      <td>0.152627</td>\n",
       "      <td>0.001608</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017991</td>\n",
       "      <td>0.499282</td>\n",
       "      <td>...</td>\n",
       "      <td>0.454397</td>\n",
       "      <td>0.001930</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005898</td>\n",
       "      <td>0.418290</td>\n",
       "      <td>0.047789</td>\n",
       "      <td>0.001376</td>\n",
       "      <td>0.743184</td>\n",
       "      <td>0.15182</td>\n",
       "      <td>0.058838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003587</td>\n",
       "      <td>0.003283</td>\n",
       "      <td>0.003083</td>\n",
       "      <td>0.003756</td>\n",
       "      <td>0.011551</td>\n",
       "      <td>0.454397</td>\n",
       "      <td>0.001930</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005898</td>\n",
       "      <td>0.418290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.483667</td>\n",
       "      <td>0.002252</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006118</td>\n",
       "      <td>0.419270</td>\n",
       "      <td>0.063409</td>\n",
       "      <td>0.001679</td>\n",
       "      <td>0.760774</td>\n",
       "      <td>0.15182</td>\n",
       "      <td>0.083439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003862</td>\n",
       "      <td>0.003587</td>\n",
       "      <td>0.003144</td>\n",
       "      <td>0.004055</td>\n",
       "      <td>0.015802</td>\n",
       "      <td>0.483667</td>\n",
       "      <td>0.002252</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006118</td>\n",
       "      <td>0.419270</td>\n",
       "      <td>...</td>\n",
       "      <td>0.557376</td>\n",
       "      <td>0.001448</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004710</td>\n",
       "      <td>0.411143</td>\n",
       "      <td>0.085457</td>\n",
       "      <td>0.001884</td>\n",
       "      <td>0.732300</td>\n",
       "      <td>0.15182</td>\n",
       "      <td>0.071119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005367</td>\n",
       "      <td>0.003862</td>\n",
       "      <td>0.004754</td>\n",
       "      <td>0.004387</td>\n",
       "      <td>0.022128</td>\n",
       "      <td>0.557376</td>\n",
       "      <td>0.001448</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004710</td>\n",
       "      <td>0.411143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.447703</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004414</td>\n",
       "      <td>0.411241</td>\n",
       "      <td>0.106870</td>\n",
       "      <td>0.004816</td>\n",
       "      <td>0.682717</td>\n",
       "      <td>0.15182</td>\n",
       "      <td>0.080230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.003355</td>\n",
       "      <td>0.005367</td>\n",
       "      <td>0.005031</td>\n",
       "      <td>0.002056</td>\n",
       "      <td>0.031220</td>\n",
       "      <td>0.447703</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004414</td>\n",
       "      <td>0.411241</td>\n",
       "      <td>...</td>\n",
       "      <td>0.605909</td>\n",
       "      <td>0.002011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000530</td>\n",
       "      <td>0.412416</td>\n",
       "      <td>0.111119</td>\n",
       "      <td>0.007271</td>\n",
       "      <td>0.716469</td>\n",
       "      <td>0.15182</td>\n",
       "      <td>0.067833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   var1(t-1)  var2(t-1)  var3(t-1)  var4(t-1)  var5(t-1)  var6(t-1)  \\\n",
       "1   0.003283   0.002811   0.002673   0.003249   0.003761   0.152627   \n",
       "2   0.003587   0.003283   0.003083   0.003756   0.011551   0.454397   \n",
       "3   0.003862   0.003587   0.003144   0.004055   0.015802   0.483667   \n",
       "4   0.005367   0.003862   0.004754   0.004387   0.022128   0.557376   \n",
       "5   0.003355   0.005367   0.005031   0.002056   0.031220   0.447703   \n",
       "\n",
       "   var7(t-1)  var8(t-1)  var9(t-1)  var10(t-1)  ...   var6(t)   var7(t)  \\\n",
       "1   0.001608        0.0   0.017991    0.499282  ...  0.454397  0.001930   \n",
       "2   0.001930        0.0   0.005898    0.418290  ...  0.483667  0.002252   \n",
       "3   0.002252        0.0   0.006118    0.419270  ...  0.557376  0.001448   \n",
       "4   0.001448        0.0   0.004710    0.411143  ...  0.447703  0.000322   \n",
       "5   0.000322        0.0   0.004414    0.411241  ...  0.605909  0.002011   \n",
       "\n",
       "   var8(t)   var9(t)  var10(t)  var11(t)  var12(t)  var13(t)  var14(t)  \\\n",
       "1      0.0  0.005898  0.418290  0.047789  0.001376  0.743184   0.15182   \n",
       "2      0.0  0.006118  0.419270  0.063409  0.001679  0.760774   0.15182   \n",
       "3      0.0  0.004710  0.411143  0.085457  0.001884  0.732300   0.15182   \n",
       "4      0.0  0.004414  0.411241  0.106870  0.004816  0.682717   0.15182   \n",
       "5      0.0  0.000530  0.412416  0.111119  0.007271  0.716469   0.15182   \n",
       "\n",
       "   var15(t)  \n",
       "1  0.058838  \n",
       "2  0.083439  \n",
       "3  0.071119  \n",
       "4  0.080230  \n",
       "5  0.067833  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reframed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 1460 into shape (1460,1,14)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11888/1704156439.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# reshape input to be 3D [samples, timesteps, features]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mtrain_X\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m14\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mtest_X\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m14\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mreshape\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ML\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mreshape\u001b[1;34m(a, newshape, order)\u001b[0m\n\u001b[0;32m    299\u001b[0m            [5, 6]])\n\u001b[0;32m    300\u001b[0m     \"\"\"\n\u001b[1;32m--> 301\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'reshape'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ML\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 1460 into shape (1460,1,14)"
     ]
    }
   ],
   "source": [
    "# split data\n",
    "values = reframed.values\n",
    "n_train_days = 365 * 4\n",
    "train = values[:n_train_days, :]\n",
    "test = values[n_train_days:, :]\n",
    "\n",
    "# split into input and outputs\n",
    "train_X, train_y = train[:, :1], train[:, 1]\n",
    "test_X, test_y = test[:, :1], test[:, 1]\n",
    "\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, 14))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, 14))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "21/21 - 1s - loss: 0.0712 - val_loss: 0.0316\n",
      "Epoch 2/10\n",
      "21/21 - 0s - loss: 0.0457 - val_loss: 0.0766\n",
      "Epoch 3/10\n",
      "21/21 - 0s - loss: 0.0372 - val_loss: 0.0901\n",
      "Epoch 4/10\n",
      "21/21 - 0s - loss: 0.0348 - val_loss: 0.0741\n",
      "Epoch 5/10\n",
      "21/21 - 0s - loss: 0.0334 - val_loss: 0.0539\n",
      "Epoch 6/10\n",
      "21/21 - 0s - loss: 0.0330 - val_loss: 0.0430\n",
      "Epoch 7/10\n",
      "21/21 - 0s - loss: 0.0298 - val_loss: 0.0433\n",
      "Epoch 8/10\n",
      "21/21 - 0s - loss: 0.0286 - val_loss: 0.0416\n",
      "Epoch 9/10\n",
      "21/21 - 0s - loss: 0.0279 - val_loss: 0.0290\n",
      "Epoch 10/10\n",
      "21/21 - 0s - loss: 0.0277 - val_loss: 0.0211\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create model\n",
    "# design network\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from matplotlib import pyplot\n",
    "\n",
    "try:\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mae', optimizer='adam')\n",
    "    # fit network\n",
    "    history = model.fit(train_X, train_y, epochs=10, batch_size=72,\n",
    "                        validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "\n",
    "    # plot history\n",
    "    pyplot.plot(history.history['loss'], label='train')\n",
    "    pyplot.plot(history.history['val_loss'], label='test')\n",
    "    pyplot.legend()\n",
    "    pyplot.show()\n",
    "except Exception as e:\n",
    "    print(\"Error: \", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.04290769]\n",
      " [0.03547386]\n",
      " [0.0706437 ]\n",
      " [0.08363149]\n",
      " [0.07180008]\n",
      " [0.06866653]\n",
      " [0.06886155]\n",
      " [0.0807102 ]\n",
      " [0.06870137]\n",
      " [0.06830999]\n",
      " [0.07556157]\n",
      " [0.08263546]\n",
      " [0.06665047]\n",
      " [0.0641987 ]\n",
      " [0.06428431]\n",
      " [0.03794074]\n",
      " [0.04787261]\n",
      " [0.05867606]\n",
      " [0.0507577 ]\n",
      " [0.04821431]\n",
      " [0.05212659]\n",
      " [0.06170459]\n",
      " [0.03500137]\n",
      " [0.02070243]\n",
      " [0.04245714]\n",
      " [0.04403954]\n",
      " [0.04350322]\n",
      " [0.05470092]\n",
      " [0.06015826]\n",
      " [0.05080983]\n",
      " [0.0383274 ]\n",
      " [0.04639217]\n",
      " [0.05739788]\n",
      " [0.0493312 ]\n",
      " [0.05266562]\n",
      " [0.04795906]\n",
      " [0.02496203]\n",
      " [0.03904217]\n",
      " [0.0605232 ]\n",
      " [0.0736244 ]\n",
      " [0.08205202]\n",
      " [0.06865062]\n",
      " [0.07010753]\n",
      " [0.04150724]\n",
      " [0.05368439]\n",
      " [0.06333574]\n",
      " [0.0551082 ]\n",
      " [0.06841332]\n",
      " [0.06764205]\n",
      " [0.06371186]\n",
      " [0.04767413]\n",
      " [0.06187408]\n",
      " [0.08027225]\n",
      " [0.083542  ]\n",
      " [0.08487294]\n",
      " [0.06148337]\n",
      " [0.05454344]\n",
      " [0.03986877]\n",
      " [0.0329898 ]\n",
      " [0.05964863]\n",
      " [0.06031999]\n",
      " [0.05237814]\n",
      " [0.04935825]\n",
      " [0.05820078]\n",
      " [0.02942944]\n",
      " [0.03100743]\n",
      " [0.05219365]\n",
      " [0.05029681]\n",
      " [0.05847362]\n",
      " [0.05703803]\n",
      " [0.06153264]\n",
      " [0.03892075]\n",
      " [0.04770641]\n",
      " [0.05815845]\n",
      " [0.06024309]\n",
      " [0.05849641]\n",
      " [0.05778394]\n",
      " [0.0509291 ]\n",
      " [0.02888293]\n",
      " [0.02653546]\n",
      " [0.04901306]\n",
      " [0.04747532]\n",
      " [0.04530901]\n",
      " [0.04984968]\n",
      " [0.04856722]\n",
      " [0.03184143]\n",
      " [0.01755146]\n",
      " [0.04708581]\n",
      " [0.04515429]\n",
      " [0.04448051]\n",
      " [0.04191319]\n",
      " [0.0328575 ]\n",
      " [0.01904749]\n",
      " [0.02292166]\n",
      " [0.03094499]\n",
      " [0.03380575]\n",
      " [0.034196  ]\n",
      " [0.03364431]\n",
      " [0.04064779]\n",
      " [0.02103368]\n",
      " [0.02489947]\n",
      " [0.04418026]\n",
      " [0.04030088]\n",
      " [0.04647766]\n",
      " [0.05168203]\n",
      " [0.03696319]\n",
      " [0.04299387]\n",
      " [0.06340229]\n",
      " [0.07087166]\n",
      " [0.07511993]\n",
      " [0.05688949]\n",
      " [0.06363183]\n",
      " [0.05485089]\n",
      " [0.03716195]\n",
      " [0.03180919]\n",
      " [0.04884229]\n",
      " [0.05835527]\n",
      " [0.04489159]\n",
      " [0.05372828]\n",
      " [0.05696474]\n",
      " [0.03223518]\n",
      " [0.03077053]\n",
      " [0.04637321]\n",
      " [0.04957253]\n",
      " [0.05105089]\n",
      " [0.06064608]\n",
      " [0.05925326]\n",
      " [0.03521441]\n",
      " [0.0422444 ]\n",
      " [0.06464515]\n",
      " [0.06060208]\n",
      " [0.05696866]\n",
      " [0.05559729]\n",
      " [0.06105863]\n",
      " [0.03200002]\n",
      " [0.05108533]\n",
      " [0.07236113]\n",
      " [0.05971193]\n",
      " [0.06365561]\n",
      " [0.08408847]\n",
      " [0.08137408]\n",
      " [0.05341453]\n",
      " [0.05292653]\n",
      " [0.07060777]\n",
      " [0.05761052]\n",
      " [0.06403624]\n",
      " [0.05189655]\n",
      " [0.04629581]\n",
      " [0.02952022]\n",
      " [0.0541157 ]\n",
      " [0.0592628 ]\n",
      " [0.05092413]\n",
      " [0.0461725 ]\n",
      " [0.04184067]\n",
      " [0.04669817]\n",
      " [0.03043744]\n",
      " [0.02972784]\n",
      " [0.04928742]\n",
      " [0.0539826 ]\n",
      " [0.0535075 ]\n",
      " [0.06634136]\n",
      " [0.06257954]\n",
      " [0.03648167]\n",
      " [0.02174076]\n",
      " [0.05589467]\n",
      " [0.06329936]\n",
      " [0.06103083]\n",
      " [0.05956496]\n",
      " [0.0578983 ]\n",
      " [0.03399137]\n",
      " [0.03846007]\n",
      " [0.06485705]\n",
      " [0.07208082]\n",
      " [0.07919619]\n",
      " [0.06861874]\n",
      " [0.0638828 ]\n",
      " [0.03807971]\n",
      " [0.03462473]\n",
      " [0.07003202]\n",
      " [0.06396583]\n",
      " [0.06427473]\n",
      " [0.06530663]\n",
      " [0.06751222]\n",
      " [0.04285552]\n",
      " [0.05386048]\n",
      " [0.07286903]\n",
      " [0.07043951]\n",
      " [0.07077414]\n",
      " [0.07511941]\n",
      " [0.07222074]\n",
      " [0.0397427 ]\n",
      " [0.03135495]\n",
      " [0.0705961 ]\n",
      " [0.07571737]\n",
      " [0.07299735]\n",
      " [0.06935339]\n",
      " [0.07333226]\n",
      " [0.04648457]\n",
      " [0.03076551]\n",
      " [0.06341965]\n",
      " [0.06641649]\n",
      " [0.07750301]\n",
      " [0.07364451]\n",
      " [0.06955433]\n",
      " [0.04508142]\n",
      " [0.0402773 ]\n",
      " [0.07779415]\n",
      " [0.09585019]\n",
      " [0.08589382]\n",
      " [0.08891368]\n",
      " [0.07964451]\n",
      " [0.0521669 ]\n",
      " [0.04696177]\n",
      " [0.07489252]\n",
      " [0.08073755]\n",
      " [0.08191675]\n",
      " [0.08111431]\n",
      " [0.08078986]\n",
      " [0.05227725]\n",
      " [0.05251   ]\n",
      " [0.08223936]\n",
      " [0.08368441]\n",
      " [0.0826983 ]\n",
      " [0.07991158]\n",
      " [0.07871774]\n",
      " [0.05534222]\n",
      " [0.0459099 ]\n",
      " [0.07171725]\n",
      " [0.07363214]\n",
      " [0.07478208]\n",
      " [0.07711109]\n",
      " [0.0806829 ]\n",
      " [0.05419257]\n",
      " [0.04085906]\n",
      " [0.07522935]\n",
      " [0.07676268]\n",
      " [0.08097375]\n",
      " [0.07396671]\n",
      " [0.0685697 ]\n",
      " [0.04050145]\n",
      " [0.03239457]\n",
      " [0.06348205]\n",
      " [0.0705758 ]\n",
      " [0.07150418]\n",
      " [0.07368658]\n",
      " [0.07047354]\n",
      " [0.04266574]\n",
      " [0.05495695]\n",
      " [0.07295343]\n",
      " [0.07057978]\n",
      " [0.08369251]\n",
      " [0.08041617]\n",
      " [0.080642  ]\n",
      " [0.04395001]\n",
      " [0.02569558]\n",
      " [0.06282085]\n",
      " [0.06850491]\n",
      " [0.0630652 ]\n",
      " [0.06834146]\n",
      " [0.06533459]\n",
      " [0.03695999]\n",
      " [0.03078812]\n",
      " [0.06197122]\n",
      " [0.06906837]\n",
      " [0.07711075]\n",
      " [0.06833154]\n",
      " [0.06436805]\n",
      " [0.05764599]\n",
      " [0.05310129]\n",
      " [0.07964741]\n",
      " [0.07089264]\n",
      " [0.07360291]\n",
      " [0.06498158]\n",
      " [0.05300055]\n",
      " [0.04415074]\n",
      " [0.02374844]\n",
      " [0.05816678]\n",
      " [0.0612161 ]\n",
      " [0.06188373]\n",
      " [0.07806604]\n",
      " [0.07137559]\n",
      " [0.04257504]\n",
      " [0.02920663]\n",
      " [0.06319165]\n",
      " [0.06809425]\n",
      " [0.06922012]\n",
      " [0.06483654]\n",
      " [0.07124398]\n",
      " [0.04732031]\n",
      " [0.04264659]\n",
      " [0.06986324]\n",
      " [0.07544892]\n",
      " [0.0688071 ]\n",
      " [0.0734032 ]\n",
      " [0.06990604]\n",
      " [0.03557795]\n",
      " [0.03629811]\n",
      " [0.06444928]\n",
      " [0.05884337]\n",
      " [0.06528248]\n",
      " [0.06617538]\n",
      " [0.07152446]\n",
      " [0.03570255]\n",
      " [0.03360669]\n",
      " [0.06223368]\n",
      " [0.05788958]\n",
      " [0.05883285]\n",
      " [0.05458982]\n",
      " [0.05704153]\n",
      " [0.02322483]\n",
      " [0.0213516 ]\n",
      " [0.06001369]\n",
      " [0.06429006]\n",
      " [0.06159438]\n",
      " [0.05990024]\n",
      " [0.05688275]\n",
      " [0.02807609]\n",
      " [0.01972595]\n",
      " [0.05170454]\n",
      " [0.05954639]\n",
      " [0.05996159]\n",
      " [0.06174124]\n",
      " [0.06035218]\n",
      " [0.02880157]\n",
      " [0.01996019]\n",
      " [0.05699873]\n",
      " [0.05731304]\n",
      " [0.05728795]\n",
      " [0.05354008]\n",
      " [0.06108908]\n",
      " [0.02670381]\n",
      " [0.01948114]\n",
      " [0.05623575]\n",
      " [0.05490323]\n",
      " [0.0600406 ]\n",
      " [0.05610345]\n",
      " [0.05088737]\n",
      " [0.03469389]\n",
      " [0.03212225]\n",
      " [0.05410413]\n",
      " [0.04886077]\n",
      " [0.0482361 ]\n",
      " [0.0498217 ]\n",
      " [0.04589562]\n",
      " [0.01227584]\n",
      " [0.00103903]\n",
      " [0.04109853]\n",
      " [0.04744232]\n",
      " [0.04110505]\n",
      " [0.04585022]\n",
      " [0.05101557]\n",
      " [0.01403213]\n",
      " [0.00012737]\n",
      " [0.03401171]\n",
      " [0.03195383]\n",
      " [0.03304061]\n",
      " [0.04041998]\n",
      " [0.02942376]\n",
      " [0.01304499]\n",
      " [0.00114972]\n",
      " [0.03666819]\n",
      " [0.03879299]\n",
      " [0.04512791]\n",
      " [0.03814777]\n",
      " [0.04828133]]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    yhat = model.predict(test_X)\n",
    "    print(yhat)\n",
    "except Exception as e:\n",
    "    print(\"Error: \")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.64400546e+03, 3.64404392e+03, 3.74779329e+03, ...,\n",
       "        6.30802898e+00, 8.11913800e+00, 7.09999490e+03],\n",
       "       [3.14761077e+03, 3.14764257e+03, 3.24104381e+03, ...,\n",
       "        6.30126717e+00, 7.40549054e+00, 6.13637009e+03],\n",
       "       [5.49608072e+03, 5.49614404e+03, 5.63850285e+03, ...,\n",
       "        6.33325765e+00, 1.07817951e+01, 1.06953309e+04],\n",
       "       ...,\n",
       "       [3.79226120e+03, 3.79230165e+03, 3.89914165e+03, ...,\n",
       "        6.31004849e+00, 8.33227955e+00, 7.38779594e+03],\n",
       "       [3.32616135e+03, 3.32619554e+03, 3.42331895e+03, ...,\n",
       "        6.30369935e+00, 7.66218580e+00, 6.48298089e+03],\n",
       "       [4.00283099e+03, 4.00287426e+03, 4.11410392e+03, ...,\n",
       "        6.31291684e+00, 8.63500760e+00, 7.79656396e+03]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "def inverse_transform(X, scaler):\n",
    "    # Get something which has as many features as dataset\n",
    "    extended = np.zeros((len(X), 15))\n",
    "    # Put the predictions there\n",
    "    extended[:, 0:] = X\n",
    "    # Inverse transform it and select the 3rd column.\n",
    "    return scaler.inverse_transform(extended)[:, :]\n",
    "\n",
    "inverse_transform(yhat, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (365,29) (15,) (365,29) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11888/193544198.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\ML\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36minverse_transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    527\u001b[0m         )\n\u001b[0;32m    528\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 529\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    530\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m/=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (365,29) (15,) (365,29) "
     ]
    }
   ],
   "source": [
    "z = np.concatenate((yhat, test_X.reshape((test_X.shape[0], test_X.shape[2]))[:, 1:]), axis=1)\n",
    "scaler.inverse_transform(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # invert scaling for forecast\n",
    "    # test_X_ = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "    inv_yhat = concatenate((yhat, test_X[:, 1:]), axis=1)\n",
    "    inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "    inv_yhat = inv_yhat[:, 0]\n",
    "\n",
    "    # invert scaling for actual\n",
    "    test_y = test_y.reshape((len(test_y), 1))\n",
    "    inv_y = concatenate((test_y, test_X[:, 1:]), axis=1)\n",
    "    inv_y = scaler.inverse_transform(inv_y)\n",
    "    inv_y = inv_y[:, 0]\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Error: \", e)\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model summary\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "\n",
    "try:\n",
    "    yhat = model.predict(test_X)\n",
    "    test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "\n",
    "    # invert scaling for forecast\n",
    "    inv_yhat = concatenate((yhat, test_X[:, 1:]), axis=1)\n",
    "    inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "    inv_yhat = inv_yhat[:, 0]\n",
    "\n",
    "    # invert scaling for actual\n",
    "    test_y = test_y.reshape((len(test_y), 1))\n",
    "    inv_y = concatenate((test_y, test_X[:, 1:]), axis=1)\n",
    "    inv_y = scaler.inverse_transform(inv_y)\n",
    "    inv_y = inv_y[:, 0]\n",
    "\n",
    "    # calculate RMSE\n",
    "    rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "    print('Test RMSE: %.3f' % rmse)\n",
    "except Exception as e:\n",
    "    print(\"Error: \", e)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ea81ae92a58e0688f48f2fcfa3a5f0d8c10798c4cde0919c77c6301d45da8892"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('ML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
