{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``https://github.com/hhk998402/Time-Series-Forecasting-SARIMAX/blob/master/Hemant_Sangam.ipynb``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Approach used:</b> SARIMAX (Seasonal Autoregressive Integrated Moving Average with eXogeneous variables)\n",
    "\n",
    "<b> Reason:</b> The data provided is seasonal, and it is a time series data with multiple exogeneous variables influencing the result. Hence, the optimal statistical model that can be applied to this task is SARIMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open and store the dataset as a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "df = pd.read_csv(\"../complete-merged-df.csv\", index_col=0, parse_dates=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the data:\n",
    "\n",
    "- Split the data into train and test samples\n",
    "- Create `endog` and `exog` variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test\n",
    "top_predictors = ['close','open', 'high', 'low', 'n-transactions', 'cost-per-transaction',\n",
    "                  'Gold price', 'output-volume',  'USD-CNY Price', 'SVI', 'Wikiviews']\n",
    "df = df[top_predictors]\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.2, shuffle=False)\n",
    "# len(train), len(test)\n",
    "\n",
    "# Variables\n",
    "exog_data = train.drop(['close'], axis=1)\n",
    "\n",
    "exog = sm.add_constant(exog_data)\n",
    "endog = train[['close']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the best order for the ARIMA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial approximation of parameters\n",
    "Qs = range(0, 2)\n",
    "qs = range(0, 3)\n",
    "Ps = range(0, 3)\n",
    "ps = range(0, 3)\n",
    "D = 1\n",
    "d = 1\n",
    "parameters = itertools.product(ps, qs, Ps, Qs)\n",
    "parameters_list = list(parameters)\n",
    "len(parameters_list)\n",
    "\n",
    "# Model Selection\n",
    "results = []\n",
    "best_aic = float(\"inf\")\n",
    "warnings.filterwarnings('ignore')\n",
    "for param in parameters_list:\n",
    "    try:\n",
    "        model = SARIMAX(endog, exog=exog, order=(param[0], d, param[1]), seasonal_order=(param[2], D, param[3], 4)).fit(disp=-1)\n",
    "    except ValueError:\n",
    "        print('bad parameter combination:', param)\n",
    "        continue\n",
    "    aic = model.aic\n",
    "    if aic < best_aic:\n",
    "        best_model = model\n",
    "        best_aic = aic\n",
    "        best_param = param\n",
    "    results.append([param, model.aic])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Models\n",
    "result_table = pd.DataFrame(results)\n",
    "result_table.columns = ['parameters', 'aic']\n",
    "print(result_table.sort_values(by='aic', ascending=True).head())\n",
    "print(best_model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model with the train variables with order `(p=1, d=0, q=1)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "mod = SARIMAX(endog, exog=exog, order=(1, 1, 2), seasonal_order=(0, 1, 1, 4))\n",
    "fit_res = mod.fit(disp=False)\n",
    "fit_res.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breakdown of the summary order=(1, 0, 1)\n",
    "- The Ljung-Box (L1) (Q) at lag 1 is 0, and the Prob(Q) is 0.99. Since the probability is above 0.05, we can't reject the null that the errors are white noise.\n",
    "- Heteroscedasticity tests that the error residuals are homoscedastic or have the same variance. Our summary statistics show a test statistic of 0.65 and a p-value of 0.00, which means we reject the null hypothesis and our residuals show variance.\n",
    "- Jarque-Bera tests for the normality of errors. It tests the null that the data is normally distributed against an alternative of another distribution. We see a test statistic of `13286.64` with a probability of 0, which means we reject the null hypothesis, and the data is not normally distributed. Also, as part of the Jarque-Bera test, we see the distribution has a slight negative skew and a large kurtosis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adfuller test\n",
    "print(\"Dickeyâ€“Fuller test:: p=%f\" % sm.tsa.adfuller(fit_res.resid[13:])[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the residuals from the model fit in acf and pacf plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = fit_res.resid\n",
    "fig, ax = plt.subplots(2, 1, figsize=(15, 8))\n",
    "fig = sm.graphics.tsa.plot_acf(res, lags=50, ax=ax[0])\n",
    "fig = sm.graphics.tsa.plot_pacf(res, lags=50, ax=ax[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame(fit_res.resid, columns=['resid'])\n",
    "res_df.sort_values(by='resid', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outlier in date `2017-12-22`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_res.plot_diagnostics(figsize=(12, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residual analysis of the selected model\n",
    "- We can see that the residuals have no trend and a fairly constant variance over time, just like white noise. \n",
    "- On the top right plot, the distribution of residuals is very close to a normal distribution. \n",
    "- This is further supported by the Q-Q plot on the bottom left that shows a fairly straight line that lies on y = x. \n",
    "- Finally, the correlogram shows no significant coefficients after lag 0, just like white noise. \n",
    "\n",
    "Therefore, from a graphical analysis, the residuals of this model resemble white noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy metrics\n",
    "def forecast_accuracy(forecast, actual):\n",
    "    mape = np.mean(np.abs(forecast - actual)/np.abs(actual))  # MAPE\n",
    "    me = np.mean(forecast - actual)             # ME\n",
    "    mae = np.mean(np.abs(forecast - actual))    # MAE\n",
    "    mpe = np.mean((forecast - actual)/actual)   # MPE\n",
    "    rmse = np.mean((forecast - actual)**2)**.5  # RMSE\n",
    "    corr = np.corrcoef(forecast, actual)[0, 1]   # corr\n",
    "    mins = np.amin(np.hstack([forecast[:, None],\n",
    "                              actual[:, None]]), axis=1)\n",
    "    maxs = np.amax(np.hstack([forecast[:, None],\n",
    "                              actual[:, None]]), axis=1)\n",
    "    minmax = 1 - np.mean(mins/maxs)             # minmax\n",
    "    \n",
    "    return({'mape': mape, 'me': me, 'mae': mae,\n",
    "            'mpe': mpe, 'rmse': rmse, \n",
    "            'corr': corr, 'minmax': minmax})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now lets test the model's prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test model\n",
    "first_predict, last_predict = test.iloc[0].name, test.iloc[-1].name\n",
    "\n",
    "exog1 = (sm.add_constant(test).loc[first_predict:])\n",
    "exog1 = exog1.drop(['close'], axis=1)\n",
    "\n",
    "forecast = fit_res.forecast(steps=len(test), exog=exog1)\n",
    "print(len(forecast), len(test))\n",
    "\n",
    "result_data = pd.DataFrame(index=test.index, columns=['actual', 'pred'])\n",
    "# result_data.head()\n",
    "\n",
    "chk = 0\n",
    "for i in tqdm(forecast):\n",
    "    result_data.iloc[chk][\"actual\"] = df.iloc[df.index == test.iloc[chk].name]['close'].values[0]\n",
    "    result_data.iloc[chk][\"pred\"] = i\n",
    "    chk += 1\n",
    "    \n",
    "result_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the values at a random date from the dataset\n",
    "sample_date = test.iloc[5].name\n",
    "y_hat = df.loc[sample_date]['close']\n",
    "y_pred = result_data[result_data.index == sample_date][\"pred\"].values[0]\n",
    "\n",
    "# compare that date with the predicted date\n",
    "print(F\"{sample_date}\\n\\tActual {y_hat}\\n\\tPredicted {y_pred}\")\n",
    "\n",
    "# display the forecast accuracy metrics for the test set\n",
    "forecast_accuracy(forecast, test['close'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the predicted value is quite close to the actual value on that date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the test data and the predicted data\n",
    "plt.plot(df['close'], label='test', color='blue')\n",
    "plt.plot(result_data['pred'], label='predicted', color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The blue label depicts the actual values, while the red label shows the prediction made. <br>\n",
    "The plot shows us the model has predicted the values closely to the actual values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecast Tests\n",
    "- Make a prediction using the model for the next `n-days/months/years`.\n",
    "- The `get_new_data()` function gets the BPI from Yahoo Finance for the latest/given dates to compare with the predictions.\n",
    "- Create a `future` DataFrame with the actual and forecasted values\n",
    "- Create a mask for a short time frame and visualize it in a plot\n",
    "- Calculate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "n_years = 2\n",
    "n_days = 365*n_years+1\n",
    "\n",
    "exog_last = sm.add_constant(df.drop(['close'], axis=1))[-n_days:]\n",
    "start_index = exog.index.max().date() + relativedelta(days=1)\n",
    "end_index = date(start_index.year+n_years, start_index.month, start_index.day)\n",
    "pred = fit_res.predict(start=start_index, end=end_index, exog=exog_last)\n",
    "\n",
    "print(start_index, end_index)\n",
    "try:\n",
    "    print(f\"Forecast {pred.iloc[pred.index == '2022-01-05']}\")\n",
    "    # print(f\"Actual {df.loc['2021-01-05']['close']}\")\n",
    "except IndexError as e:\n",
    "    print(f\"Cannot find the forecast date (max {end_index})\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "from yahoofinancials import YahooFinancials\n",
    "\n",
    "# get new data from yahoo finance\n",
    "def get_new_data(ticker, start_date, end_date=date.today()):\n",
    "    data = yf.download(ticker, start=start_date, end=end_date, progress=False)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yf_df = get_new_data('BTC-USD', '2020-12-31', '2022-03-20')\n",
    "\n",
    "# create a new dataframe with the actual and predicted values\n",
    "future = pd.DataFrame(columns=['actual', 'pred', 'train', 'forecast'])\n",
    "future['forecast'] = pred\n",
    "future[\"actual\"] = yf_df['Close']\n",
    "future[\"pred\"] = result_data['pred']\n",
    "future['train'] = df['close']\n",
    "future\n",
    "# yf_df['Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare predicted values with actual values\n",
    "mask = (future.index >= '2021-12-01') & (future.index <= '2022-04-30')\n",
    "filter = future.loc[mask]\n",
    "filter.plot(figsize=(12, 6), title='Bitcoin Price Prediction', grid=True, legend=True, fontsize=12)\n",
    "\n",
    "# The lower the MSE, the better the forecast.\n",
    "forecast_accuracy(filter['forecast'], filter['actual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future.plot(figsize=(12, 6))\n",
    "\n",
    "# yf_df.iloc[yf_df.index >= '2021-12-01']['Close'].plot(figsize=(12, 6), label='actual', color='blue')\n",
    "# result_data.iloc[result_data.index >= '2021-12-01']['pred'].plot(figsize=(12, 6), label='predicted', color='red')\n",
    "# pred.iloc[pred.index >=\n",
    "#           '2021-12-01'].plot(figsize=(12, 6), label='Forecasted', color='green')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results indicate that the model is still a little rough and not something we should use as trading advice, but that was not unexpected due to the extremely volatile nature of cryptocurrencies, especially in the last 6 months.\n",
    "\n",
    "It is probably also not such a good idea to try and predict 6 months into the future as we can see how insane even the 80% confidence interval becomes out this far. Maybe sticking to 1 month advance predictitons is more sensible. Or maybe even predicting on a daily basis."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ea81ae92a58e0688f48f2fcfa3a5f0d8c10798c4cde0919c77c6301d45da8892"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('ML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
