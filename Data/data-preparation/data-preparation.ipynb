{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../complete-merged-df.csv\", index_col=0, parse_dates=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.columns), df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"NaN values: \",len(df[df.isna().any(axis=1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=5, ncols=3, dpi=300, figsize=(11, 6))\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()[:15]):\n",
    "    data = df[df.columns[i]]\n",
    "\n",
    "    ax.plot(data, color='black', linewidth=1)\n",
    "    ax.set_title(df.columns[i])\n",
    "    ax.xaxis.set_ticks_position('none')\n",
    "    ax.yaxis.set_ticks_position('none')\n",
    "    ax.spines['top'].set_alpha(0)\n",
    "    ax.tick_params(labelsize=6)\n",
    "\n",
    "fig.autofmt_xdate()\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import linregress\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def correlation_test(v1,v2, graph=False):\n",
    "    coef = np.corrcoef(v1, v2)\n",
    "    linreg = linregress(v1, v2)\n",
    "    print(\"Coef : \", coef)\n",
    "    print(\"Linear Regression results : \")\n",
    "    print(f\"\\tp = {round(linreg.pvalue,5)}\")\n",
    "    print(f\"\\tslope = {round(linreg.slope,5)}\")\n",
    "    print(f\"\\tintercept = {round(linreg.intercept,5)}\")\n",
    "    print(f\"\\tstd. err = {round(linreg.stderr, 5)}\")\n",
    "    print(\"-----------------------------\")\n",
    "    if graph:\n",
    "        plt.scatter(v1, v2)\n",
    "        plt.show()\n",
    "\n",
    "# correlation to btc closing price and miner revenue\n",
    "def corr_plot(y_label, y_data, y2_label, y2_data, x):\n",
    "    fig, ax1= plt.subplots()\n",
    "    fig.set_figwidth(18)\n",
    "    fig.set_figheight(10)\n",
    "\n",
    "    ax1.set_xlabel('Date')\n",
    "    ax1.tick_params(axis='x', bottom=False, labelbottom=False)\n",
    "\n",
    "    ax1.set_ylabel(y_label, color='red', size='x-large')\n",
    "    ax1.tick_params(axis='y', labelcolor='red', labelsize='large')\n",
    "    ax1.plot(x, y_data, color='red')\n",
    "\n",
    "    axprecip = ax1.twinx()\n",
    "    axprecip.set_ylabel(y2_label, color='blue', size='x-large')\n",
    "    axprecip.tick_params(axis='y', labelcolor='blue', labelsize='large')\n",
    "    axprecip.plot(x, y2_data, color='blue')\n",
    "\n",
    "corr_plot(\n",
    "    \"Bitcoin Price\", df[\"close\"],\n",
    "    \"SVI\", df[\"SVI\"],\n",
    "    df.index)\n",
    "\n",
    "correlation_test(df['n-transactions'],  df['SVI'])\n",
    "correlation_test(df['close'],  df['cost-per-transaction'])\n",
    "correlation_test(df['close'],  df['hash-rate'])\n",
    "correlation_test(df['close'],  df['n-transactions'])\n",
    "correlation_test(df['close'],  df['Gold price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close price correlation matrix\n",
    "k = len(df.columns)  # number of variables for heatmap\n",
    "cols = df.corr().nlargest(k, 'close')['close'].index\n",
    "cm = df[cols].corr()\n",
    "cm.style.background_gradient(cmap='coolwarm').set_precision(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = df.values\n",
    "X = array[:, 1:15]\n",
    "Y = array[:, 0].astype('int')\n",
    "\n",
    "# print(f\"X at (0): {X[0]}\")\n",
    "# print(f\"Y at (0): {Y[0]}\")\n",
    "X.shape, Y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHI SQUARE TEST\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "import numpy as np\n",
    "\n",
    "# Feature extraction\n",
    "test = SelectKBest(score_func=chi2, k=9)\n",
    "chifit = test.fit(X, Y)\n",
    "\n",
    "# Summarize scores\n",
    "np.set_printoptions(precision=3)\n",
    "print(list(zip(df.columns[1:], chifit.scores_)))\n",
    "\n",
    "features = chifit.transform(X)\n",
    "# Summarize selected features\n",
    "# print(features[0:5, :])\n",
    "len(chifit.scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFE - Recursive Feature Elimination\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Feature extraction\n",
    "model = LinearRegression()\n",
    "rfe = RFE(model, n_features_to_select=10, step=1)\n",
    "\n",
    "fit = rfe.fit(X, Y)\n",
    "\n",
    "print(\"Num Features: %s\" % (fit.n_features_))\n",
    "# print(\"Selected Features: %s\" % (fit.support_))\n",
    "# print(\"Feature Ranking: %s\" % (fit.ranking_))\n",
    "\n",
    "features = pd.DataFrame(list(zip(df.columns[1:], fit.ranking_, fit.support_,  chifit.scores_.astype(int))), \n",
    "columns=['Features', 'Ranking', 'RFE-Support','Chi-Support'])\n",
    "features['RFE-Support'] = features['RFE-Support'].apply(lambda x: 'Selected' if x else 'Not Selected')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.sort_values(by=['Ranking'], ascending=True)[:10][\"Features\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot features by rank\n",
    "sns.barplot(x='Ranking', y='Features', data=features.sort_values(by=['Ranking']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Features: %s\" % (len(df.columns)-1))\n",
    "sns.catplot(x='RFE-Support', y='Features', data=features.sort_values(by=['RFE-Support']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KFold Gridsearch for the best number of params for a Regression model\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# step-1: create a cross-validation scheme\n",
    "folds = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "# step-2: specify range of hyperparameters to tune\n",
    "hyper_params = [{'n_features_to_select': list(range(2, 15))}]\n",
    "\n",
    "\n",
    "# step-3: perform grid search\n",
    "# 3.1 specify model\n",
    "lm = LinearRegression()\n",
    "lm.fit(X, Y)\n",
    "rfe = RFE(lm)\n",
    "\n",
    "# 3.2 call GridSearchCV()\n",
    "model_cv = GridSearchCV(estimator=rfe,\n",
    "                        param_grid=hyper_params,\n",
    "                        scoring='r2',\n",
    "                        cv=folds,\n",
    "                        verbose=1,\n",
    "                        return_train_score=True)\n",
    "model_cv.fit(X, Y)\n",
    "\n",
    "# cv results\n",
    "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
    "cv_results[[\"param_n_features_to_select\", \"mean_test_score\", \"std_test_score\",\n",
    "            \"mean_train_score\", \"std_train_score\"]].sort_values(by=[\"mean_train_score\", \"param_n_features_to_select\"], ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting cv results\n",
    "pyplot.figure(figsize=(16, 6))\n",
    "\n",
    "pyplot.plot(cv_results[\"param_n_features_to_select\"],\n",
    "         cv_results[\"mean_test_score\"])\n",
    "pyplot.plot(cv_results[\"param_n_features_to_select\"],\n",
    "         cv_results[\"mean_train_score\"])\n",
    "pyplot.xlabel('number of features')\n",
    "pyplot.ylabel('r-squared')\n",
    "pyplot.title(\"Optimal Number of Features\")\n",
    "pyplot.legend(['Test score', 'Train score'], loc='upper left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore the number of selected features for RFE\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.pipeline import Pipeline\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "\tmodels = dict()\n",
    "\n",
    "\tfor i in range(2, 15):\n",
    "\t\tmodel = LinearRegression()\n",
    "\t\trfe = RFE(estimator=LinearRegression(), n_features_to_select=i)\n",
    "\t\tmodels[str(i)] = Pipeline(steps=[('s',rfe),('m',model)])\n",
    "\treturn models\n",
    " \n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "\n",
    "# evaluate the models and store results\n",
    "folds = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "\tscores = cross_val_score(model, X, Y, scoring='r2', cv=folds)\n",
    "\t\n",
    "\tresults.append(scores)\n",
    "\tnames.append(name)\n",
    "\tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.xlabel('Number of Features')\n",
    "pyplot.ylabel('R-squared')\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [mean(x) for x in results] # calculate mean for each model score\n",
    "scores = pd.DataFrame({\"r2_score\": results, \"n_features\": names}) # store results in dataframe\n",
    "scores.sort_values(by=\"r2_score\", ascending=False)[0:3] # top 3 scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AIC\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "import statsmodels.api as sm\n",
    "\n",
    "y = df['close']  # define response variable\n",
    "\n",
    "# \n",
    "predictors = df[features['Features'][:10].values]\n",
    "X = sm.add_constant(predictors)  # add constant to predictor variables\n",
    "\n",
    "#fit regression model\n",
    "model = sm.OLS(y, X).fit()\n",
    "model.summary()  # view AIC of model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"AIC : \",model.aic)\n",
    "print(\"R2 : \",model.rsquared)\n",
    "print(\"Selected params : \",len(model.params.keys())-1)\n",
    "aic_pvalues = pd.DataFrame(model.pvalues, columns=['p-values']).drop(['const'])\n",
    "aic_pvalues['h0'] = aic_pvalues['p-values'].apply(lambda x: 'Rejected' if x < 0.05 else 'Not Rejected')\n",
    "aic_pvalues[\"p-values\"] = aic_pvalues[\"p-values\"].apply(lambda x: '%.3f' % x)\n",
    "aic_pvalues.sort_values(by='h0', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit Root Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "def make_stationary(data: pd.Series, alpha: float = 0.05, max_diff_order: int = 10) -> dict:\n",
    "    # Test to see if the time series is already stationary\n",
    "    if adfuller(data)[1] < alpha:\n",
    "        return {\n",
    "            'differencing_order': 0,\n",
    "            'time_series': np.array(data)\n",
    "        }\n",
    "\n",
    "    p_values = [] # A list to store P-Values\n",
    "    # Test for differencing orders from 1 to max_diff_order (included)\n",
    "    for i in range(1, max_diff_order + 1):\n",
    "        result = adfuller(data.diff(i).fillna(data.mean())) # Perform ADF test\n",
    "        p_values.append((i, result[1])) # Append P-value\n",
    "        \n",
    "    significant = [p for p in p_values if p[1] < alpha] # Keep only those where P-value is lower than significance level\n",
    "    significant = sorted(significant, key=lambda x: x[0]) # Sort by the differencing order\n",
    "    diff_order = significant[0][0] # Get the differencing order\n",
    "    stationary_series = data.diff(diff_order).fillna(data.mean()) # Make the time series stationary\n",
    "    \n",
    "    return {\n",
    "        'differencing_order': diff_order,\n",
    "        'time_series': np.array(stationary_series)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_stationarity(x, ax, name):\n",
    "    #Determing rolling statistics\n",
    "    rolmean = x.rolling(window=22,center=False).mean()\n",
    "\n",
    "    rolstd = x.rolling(window=12,center=False).std()\n",
    "    \n",
    "    #Plot rolling statistics:\n",
    "    ax.plot(x, color='blue',label='Original')\n",
    "    ax.plot(rolmean, color='red', label='Rolling Mean')\n",
    "    ax.plot(rolstd, color='black', label = 'Rolling Std')\n",
    "    ax.set_title(name)\n",
    "\n",
    "    #Perform Dickey Fuller test    \n",
    "    result=adfuller(x)\n",
    "\n",
    "    print('ADF Stastistic: %f'%result[0])\n",
    "    print('p-value: %f'%result[1])\n",
    "\n",
    "    for key,value in result[4].items():\n",
    "         if result[0]>value:\n",
    "            print(\"The graph is non stationery\")\n",
    "            break\n",
    "         else:\n",
    "            print(\"The graph is stationery\")\n",
    "            break;\n",
    "\n",
    "   #  print('Critical values:')\n",
    "   #  for key,value in result[4].items():\n",
    "      #   print('\\t%s: %.3f ' % (key, value))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ps = {}\n",
    "differenced_df = {}\n",
    "for i in df.columns:\n",
    "    ts = make_stationary(df[i])\n",
    "    differenced_df[i] = ts[\"time_series\"]\n",
    "    print(i, adfuller(df[i])[1])\n",
    "diff = pd.DataFrame(differenced_df)\n",
    "\n",
    "# for i in diff.columns:  \n",
    "    # print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     diff.reset_index(inplace=True)\n",
    "#     diff.drop(['index'], axis=1, inplace=True)\n",
    "#     diff[\"Date\"] = df.index\n",
    "#     diff.set_index(diff.Date, inplace=True)\n",
    "# except ValueError as e:\n",
    "#     print(\"Row indexing issue: \", e)\n",
    "\n",
    "\n",
    "# diff\n",
    "# diff.index = pd.to_datetime(diff.index)\n",
    "diff.to_csv('differenced_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2)\n",
    "\n",
    "test_stationarity(diff.close, ax=ax1, name=\"Close\")\n",
    "test_stationarity(diff.open, ax=ax2, name=\"Open\")\n",
    "test_stationarity(diff[diff.columns[7]], ax=ax3, name=diff.columns[7])\n",
    "test_stationarity(diff.SVI, ax=ax4, name=\"SVI\")\n",
    "\n",
    "for ax in fig.get_axes():\n",
    "    ax.label_outer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model sampling \n",
    "1. LSTM\n",
    "2. ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "\n",
    "#creating dataframe\n",
    "data = diff.sort_index(ascending=True, axis=0)\n",
    "\n",
    "new_data = pd.DataFrame(index=range(0,len(diff)),columns=['Date', 'Close'])\n",
    "for i in range(0,len(data)):\n",
    "    new_data['Date'][i] = data.index[i]\n",
    "    new_data['Close'][i] = data['close'][i]\n",
    "\n",
    "#setting index\n",
    "new_data.index = new_data.Date\n",
    "new_data.drop('Date', axis=1, inplace=True)\n",
    "\n",
    "#creating train and test sets\n",
    "dataset = data.values\n",
    "\n",
    "n_train_days = 365 * 4\n",
    "train = dataset[0:n_train_days,:]\n",
    "valid = dataset[n_train_days:, :]\n",
    "\n",
    "#converting dataset into x_train and y_train\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(dataset)\n",
    "\n",
    "x_train, y_train = [], []\n",
    "for i in range(60,len(train)):\n",
    "    x_train.append(scaled_data[i-60:i,0])\n",
    "    y_train.append(scaled_data[i,0])\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "\n",
    "x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))\n",
    "\n",
    "# create and fit the LSTM network\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(x_train.shape[1],1)))\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(x_train, y_train, epochs=1, batch_size=1, verbose=2)\n",
    "\n",
    "#predicting 246 values, using past 60 from the train data\n",
    "inputs = new_data[len(new_data) - len(valid) - 60:].values\n",
    "inputs = inputs.reshape(-1,1)\n",
    "inputs  = scaler.transform(inputs)\n",
    "\n",
    "X_test = []\n",
    "for i in range(60,inputs.shape[0]):\n",
    "    X_test.append(inputs[i-60:i,0])\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "X_test = np.reshape(X_test, (X_test.shape[0],X_test.shape[1],1))\n",
    "closing_price = model.predict(X_test)\n",
    "closing_price = scaler.inverse_transform(closing_price)\n",
    "\n",
    "rms=np.sqrt(np.mean(np.power((valid-closing_price),2)))\n",
    "print(rms)\n",
    "#9.185391255263202\n",
    "\n",
    "#for plotting\n",
    "train = new_data[:987]\n",
    "valid = new_data[987:]\n",
    "valid['Predictions'] = closing_price\n",
    "plt.plot(train['Close'])\n",
    "plt.plot(valid[['Close','Predictions']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARIMA\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "import statsmodels.api as sm\n",
    "\n",
    "model = ARIMA(diff['close'], order=(1,1,2))\n",
    "model_fit=model.fit()\n",
    "model_fit.summary()\n",
    "\n",
    "pred = model_fit.predict(start=0, end=len(diff.close)+60)\n",
    "diff.close[1760:].plot(color='blue', label='Actual')\n",
    "pred[1760:].plot(color='red', label='Predicted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Future prediction\n",
    "future_dates = [df.index[-1] + DateOffset(days=x) for x in range(0, 12)]\n",
    "\n",
    "future_datest_df = pd.DataFrame(index=future_dates[1:], columns=df.columns)\n",
    "future_datest_df.tail()\n",
    "\n",
    "future_df = pd.concat([diff, future_datest_df])\n",
    "future_df['forecast'] = model_fit.predict(start=1700, end=1900, dynamic=False)\n",
    "future_df[['close', 'forecast']][1700:].plot(figsize=(12, 8))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
