{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./complete-merged-df.csv\", index_col=0, parse_dates=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"NaN values: \",len(df[df.isna().any(axis=1)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import linregress\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def correlation_test(v1,v2, graph=False):\n",
    "    coef = np.corrcoef(v1, v2)\n",
    "    linreg = linregress(v1, v2)\n",
    "    print(\"Coef : \", coef)\n",
    "    print(\"Linear Regression results : \")\n",
    "    print(f\"\\tp = {round(linreg.pvalue,5)}\")\n",
    "    print(f\"\\tslope = {round(linreg.slope,5)}\")\n",
    "    print(f\"\\tintercept = {round(linreg.intercept,5)}\")\n",
    "    print(f\"\\tstd. err = {round(linreg.stderr, 5)}\")\n",
    "    print(\"-----------------------------\")\n",
    "    if graph:\n",
    "        plt.scatter(v1, v2)\n",
    "        plt.show()\n",
    "\n",
    "# correlation to btc closing price and miner revenue\n",
    "def corr_plot(y_label, y_data, y2_label, y2_data, x):\n",
    "    fig, ax1= plt.subplots()\n",
    "    fig.set_figwidth(18)\n",
    "    fig.set_figheight(10)\n",
    "\n",
    "    ax1.set_xlabel('Date')\n",
    "    ax1.tick_params(axis='x', bottom=False, labelbottom=False)\n",
    "\n",
    "    ax1.set_ylabel(y_label, color='red', size='x-large')\n",
    "    ax1.tick_params(axis='y', labelcolor='red', labelsize='large')\n",
    "    ax1.plot(x, y_data, color='red')\n",
    "\n",
    "    axprecip = ax1.twinx()\n",
    "    axprecip.set_ylabel(y2_label, color='blue', size='x-large')\n",
    "    axprecip.tick_params(axis='y', labelcolor='blue', labelsize='large')\n",
    "    axprecip.plot(x, y2_data, color='blue')\n",
    "\n",
    "corr_plot(\n",
    "    \"Bitcoin Price\", df[\"close\"],\n",
    "    \"SVI\", df[\"SVI\"],\n",
    "    df.index)\n",
    "\n",
    "correlation_test(df['n-transactions'],  df['SVI'])\n",
    "correlation_test(df['close'],  df['cost-per-transaction'])\n",
    "correlation_test(df['close'],  df['hash-rate'])\n",
    "correlation_test(df['close'],  df['n-transactions'])\n",
    "correlation_test(df['close'],  df['Gold price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "import statsmodels.api as sm\n",
    "\n",
    "predictors = df.drop(columns=[\"close\"])\n",
    "\n",
    "y = df['close'] #define response variable\n",
    "X = sm.add_constant(predictors) #add constant to predictor variables\n",
    "\n",
    "#fit regression model\n",
    "model = sm.OLS(y, X).fit()\n",
    "model.summary() #view AIC of model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit Root Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "def make_stationary(data: pd.Series, alpha: float = 0.05, max_diff_order: int = 10) -> dict:\n",
    "    # Test to see if the time series is already stationary\n",
    "    if adfuller(data)[1] < alpha:\n",
    "        return {\n",
    "            'differencing_order': 0,\n",
    "            'time_series': np.array(data)\n",
    "        }\n",
    "\n",
    "    p_values = [] # A list to store P-Values\n",
    "    # Test for differencing orders from 1 to max_diff_order (included)\n",
    "    for i in range(1, max_diff_order + 1):\n",
    "        result = adfuller(data.diff(i).fillna(data.mean())) # Perform ADF test\n",
    "        p_values.append((i, result[1])) # Append P-value\n",
    "        \n",
    "    significant = [p for p in p_values if p[1] < alpha] # Keep only those where P-value is lower than significance level\n",
    "    significant = sorted(significant, key=lambda x: x[0]) # Sort by the differencing order\n",
    "    diff_order = significant[0][0] # Get the differencing order\n",
    "    stationary_series = data.diff(diff_order).fillna(data.mean()) # Make the time series stationary\n",
    "    \n",
    "    return {\n",
    "        'differencing_order': diff_order,\n",
    "        'time_series': np.array(stationary_series)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_stationarity(x):\n",
    "    #Determing rolling statistics\n",
    "    rolmean = x.rolling(window=22,center=False).mean()\n",
    "\n",
    "    rolstd = x.rolling(window=12,center=False).std()\n",
    "    \n",
    "    #Plot rolling statistics:\n",
    "    orig = plt.plot(x, color='blue',label='Original')\n",
    "    mean = plt.plot(rolmean, color='red', label='Rolling Mean')\n",
    "    std = plt.plot(rolstd, color='black', label = 'Rolling Std')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title('Rolling Mean & Standard Deviation')\n",
    "    plt.show(block=False)\n",
    "    \n",
    "    #Perform Dickey Fuller test    \n",
    "    result=adfuller(x)\n",
    "    print('ADF Stastistic: %f'%result[0])\n",
    "    print('p-value: %f'%result[1])\n",
    "    pvalue=result[1]\n",
    "    for key,value in result[4].items():\n",
    "         if result[0]>value:\n",
    "            print(\"The graph is non stationery\")\n",
    "            break\n",
    "         else:\n",
    "            print(\"The graph is stationery\")\n",
    "            break;\n",
    "    print('Critical values:')\n",
    "    for key,value in result[4].items():\n",
    "        print('\\t%s: %.3f ' % (key, value))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ps = {}\n",
    "differenced_df = {}\n",
    "for i in df.columns:\n",
    "    ts = make_stationary(df[i])\n",
    "    differenced_df[i] = ts[\"time_series\"]\n",
    "    print(i, adfuller(df[i])[1])\n",
    "diff = pd.DataFrame(differenced_df)\n",
    "\n",
    "for i in diff.columns:  \n",
    "    print(i)\n",
    "    test_stationarity(diff[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model sampling \n",
    "1. LSTM\n",
    "2. ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "\n",
    "#creating dataframe\n",
    "data = df.sort_index(ascending=True, axis=0)\n",
    "# new_data = pd.DataFrame(index=range(0,len(df)),columns=['Date', 'Close'])\n",
    "# for i in range(0,len(data)):\n",
    "#     new_data['Date'][i] = data.index[i]\n",
    "#     new_data['Close'][i] = data['close'][i]\n",
    "\n",
    "# #setting index\n",
    "# new_data.index = new_data.Date\n",
    "# new_data.drop('Date', axis=1, inplace=True)\n",
    "\n",
    "#creating train and test sets\n",
    "dataset = data.values\n",
    "\n",
    "train = dataset[0:987,:]\n",
    "valid = dataset[987:,:]\n",
    "\n",
    "#converting dataset into x_train and y_train\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(dataset)\n",
    "\n",
    "x_train, y_train = [], []\n",
    "for i in range(60,len(train)):\n",
    "    x_train.append(scaled_data[i-60:i,0])\n",
    "    y_train.append(scaled_data[i,0])\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "\n",
    "x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))\n",
    "\n",
    "# create and fit the LSTM network\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(x_train.shape[1],1)))\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(x_train, y_train, epochs=1, batch_size=1, verbose=2)\n",
    "\n",
    "#predicting 246 values, using past 60 from the train data\n",
    "inputs = new_data[len(new_data) - len(valid) - 60:].values\n",
    "inputs = inputs.reshape(-1,1)\n",
    "inputs  = scaler.transform(inputs)\n",
    "\n",
    "X_test = []\n",
    "for i in range(60,inputs.shape[0]):\n",
    "    X_test.append(inputs[i-60:i,0])\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "X_test = np.reshape(X_test, (X_test.shape[0],X_test.shape[1],1))\n",
    "closing_price = model.predict(X_test)\n",
    "closing_price = scaler.inverse_transform(closing_price)\n",
    "\n",
    "rms=np.sqrt(np.mean(np.power((valid-closing_price),2)))\n",
    "print(rms)\n",
    "#9.185391255263202\n",
    "\n",
    "#for plotting\n",
    "train = new_data[:987]\n",
    "valid = new_data[987:]\n",
    "valid['Predictions'] = closing_price\n",
    "plt.plot(train['Close'])\n",
    "plt.plot(valid[['Close','Predictions']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARIMA\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "import statsmodels.api as sm\n",
    "\n",
    "model = ARIMA(df['close'], order=(0,0,1))\n",
    "model_fit=model.fit()\n",
    "model_fit.summary()\n",
    "\n",
    "df['forecast']= model_fit.predict(start=90,end=103,dynamic=True)\n",
    "df[['close','forecast']].plot(figsize=(12,8), title='ARIMA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SARIMAX\n",
    "model = sm.tsa.statespace.SARIMAX(df['close'],order=(1, 1, 1), seasonal_order=(1,1,1,12))\n",
    "results = model.fit()\n",
    "\n",
    "df['forecast'] = results.predict(start=90,end=103,dynamic=True)\n",
    "df[['close','forecast']].plot(figsize=(12,8), title='SARIMAX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Future prediction\n",
    "future_dates=[df.index[-1] + DateOffset(days=x) for x in range(0,12)]\n",
    "print(future_dates)\n",
    "\n",
    "future_datest_df=pd.DataFrame(index=future_dates[1:],columns=df.columns)\n",
    "future_datest_df.tail()\n",
    "\n",
    "future_df = pd.concat([df,future_datest_df])\n",
    "future_df['forecast'] = results.predict()\n",
    "\n",
    "future_df[['close', 'forecast']].plot(figsize=(12, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "# data = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/a10.csv', parse_dates=['date'], index_col='date')\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12,12), dpi=100, sharex=True)\n",
    "\n",
    "# Usual Differencing\n",
    "axes[0].plot(df[:], label='Original Series')\n",
    "axes[0].plot(df[:].diff(1), label='Usual Differencing')\n",
    "axes[0].set_title('Usual Differencing')\n",
    "axes[0].legend(loc='upper left', fontsize=10)\n",
    "\n",
    "\n",
    "# Seasinal Dei\n",
    "axes[1].plot(df[:], label='Original Series')\n",
    "axes[1].plot(df[:].diff(12), label='Seasonal Differencing', color='green')\n",
    "axes[1].set_title('Seasonal Differencing')\n",
    "plt.legend(loc='upper left', fontsize=10)\n",
    "# plt.suptitle('', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Seasonal Index\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from dateutil.parser import parse\n",
    "\n",
    "# multiplicative seasonal component\n",
    "result_mul = seasonal_decompose(df['close'],   # 3 years\n",
    "                                model='multiplicative', \n",
    "                                extrapolate_trend='freq')\n",
    "\n",
    "seasonal_index = result_mul.seasonal[-12].to_frame()\n",
    "seasonal_index['month'] = pd.to_datetime(seasonal_index.index).month\n",
    "\n",
    "# merge with the base data\n",
    "df['month'] = df.index.month\n",
    "dfx = pd.merge(data, seasonal_index, how='left', on='month')\n",
    "dfx.columns = ['value', 'month', 'seasonal_index']\n",
    "# dfx.index = df.index  # reassign the index.\n",
    "dfx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pmdarima as pm\n",
    "\n",
    "# SARIMAX Model\n",
    "sxmodel = pm.auto_arima(dfx[['value']], exogenous=dfx[['seasonal_index']],\n",
    "                           start_p=1, start_q=1,\n",
    "                           test='adf',\n",
    "                           max_p=3, max_q=3, m=12,\n",
    "                           start_P=0, seasonal=True,\n",
    "                           d=None, D=1, trace=True,\n",
    "                           error_action='ignore',  \n",
    "                           suppress_warnings=True, \n",
    "                           stepwise=True)\n",
    "\n",
    "sxmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast\n",
    "n_periods = 24\n",
    "fitted, confint = sxmodel.predict(n_periods=n_periods, \n",
    "                                  exogenous=np.tile(seasonal_index.seasonal, 2).reshape(-1,1), \n",
    "                                  return_conf_int=True)\n",
    "\n",
    "index_of_fc = pd.date_range(data.index[-1], periods = n_periods, freq='MS')\n",
    "\n",
    "# make series for plotting purpose\n",
    "fitted_series = pd.Series(fitted, index=index_of_fc)\n",
    "lower_series = pd.Series(confint[:, 0], index=index_of_fc)\n",
    "upper_series = pd.Series(confint[:, 1], index=index_of_fc)\n",
    "\n",
    "# Plot\n",
    "plt.plot(data['value'])\n",
    "plt.plot(fitted_series, color='darkgreen')\n",
    "plt.fill_between(lower_series.index, \n",
    "                 lower_series, \n",
    "                 upper_series, \n",
    "                 color='k', alpha=.15)\n",
    "\n",
    "plt.title(\"SARIMAX Forecast of a10 - Drug Sales\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
